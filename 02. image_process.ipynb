{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import math\n",
    "import glob\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 불러오는 함수\n",
    "def read_img(path):\n",
    "    original_img = cv2.imread(path)\n",
    "    return original_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배경 이미지를 삭제하기 위한 마스크 생성\n",
    "def make_mask(original_img):\n",
    "    # change to lab for masking mask\n",
    "    img_mask = original_img.copy()\n",
    "    img_mask = cv2.cvtColor(img_mask, cv2.COLOR_RGB2BGR)\n",
    "    img_mask = cv2.cvtColor(img_mask, cv2.COLOR_RGB2Lab)\n",
    "\n",
    "    # blur\n",
    "    blur_k = int((img_mask.mean()*0.5)//2)*2+1\n",
    "    img_mask = cv2.medianBlur(img_mask, blur_k)\n",
    "\n",
    "    # change to Grayscale for threshold\n",
    "    img_mask = cv2.cvtColor(img_mask, cv2.COLOR_Lab2BGR)\n",
    "    img_mask = cv2.cvtColor(img_mask, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    if img_mask.mean() > 100:\n",
    "        th = img_mask.mean()*0.94\n",
    "    else:\n",
    "        th = img_mask.mean()\n",
    "    \n",
    "    ret, img_mask = cv2.threshold(img_mask, th, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # mask based Max value of contours\n",
    "    contours, hierarchy = cv2.findContours(img_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    max_cnt = max(contours, key=cv2.contourArea)\n",
    "    mask = np.zeros(img_mask.shape, dtype=np.uint8)\n",
    "    cv2.drawContours(mask, [max_cnt], -1, (255,255,255), -1)\n",
    "    \n",
    "    # Applying for dilation\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_RECT, (8,8))\n",
    "    mask = cv2.dilate(mask,k)\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마스크를 이용하여 원본이미지의 배경 자르기 함수\n",
    "def cut_mask(original_img, mask):\n",
    "    img_for_cut = original_img.copy()\n",
    "    height, width = img_for_cut.shape[:2]\n",
    "\n",
    "    # mask\n",
    "    mask_list = mask.tolist()\n",
    "    \n",
    "    for y in range(int(height*0.05),height):\n",
    "        if max(mask[y,int(width*0.3):int(width*0.7)]) > 0:\n",
    "            start_y = y-int(height*0.05)\n",
    "            break\n",
    "            \n",
    "    for x in range(int(width*0.05),width):\n",
    "        if max(mask[int(height*0.3):int(height*0.7),x]) > 0:\n",
    "            start_x = x-int(width*0.05)\n",
    "            break\n",
    "            \n",
    "    for x in range(int(width*0.95),-1,-1):\n",
    "        if max(mask[int(height*0.3):int(height*0.7),x]) > 0:\n",
    "            end_x = x+int(width*0.05)\n",
    "            break\n",
    "            \n",
    "    cut_index = 0\n",
    "    if mask_list[height-1][-1] == 255 or mask_list[height-1][0] == 255:\n",
    "        for n in reversed(range(height)):\n",
    "            if mask_list[n][0] == 0 or mask_list[n][-1] == 0:\n",
    "                cut_index = n\n",
    "                break\n",
    "                \n",
    "    if cut_index == 0:\n",
    "        cut_index = height\n",
    "\n",
    "    # converting color\n",
    "    img_for_cut = cv2.cvtColor(img_for_cut, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "    img_for_cut = img_for_cut[start_y:(cut_index-1),start_x:end_x]\n",
    "    mask = mask[start_y:(cut_index-1),start_x:end_x]\n",
    "\n",
    "    # remove background\n",
    "    masked = cv2.bitwise_and(img_for_cut, mask)\n",
    "\n",
    "    return masked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마스크 씌어진 이미지를 회전시키는 함수\n",
    "def img_rotation(masked):\n",
    "    before_rot_img = masked.copy()\n",
    "\n",
    "    \n",
    "    h, w = before_rot_img.shape[:2]\n",
    "    before_rot_img = cv2.cvtColor(before_rot_img, cv2.COLOR_RGB2BGR)\n",
    "    gray = cv2.cvtColor(before_rot_img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, th = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY)\n",
    "    th_li = th.tolist()\n",
    "\n",
    "\n",
    "    for i in reversed(range(h)):\n",
    "        if th_li[i][0] == 0 and th_li[i][-1] == 0:\n",
    "            lower = i\n",
    "            break\n",
    "\n",
    "    # lower = condition ; bottom = lower / img * 0.95\n",
    "\n",
    "    if lower == h - 1:\n",
    "        lower = int(h*0.9)\n",
    "\n",
    "    # upper = condition ; lower + lower * 0.05\n",
    "\n",
    "    slice5 = int(len(th)*0.05)\n",
    "    upper = lower - slice5\n",
    "\n",
    "    # x, y = between upper and lower (5%) / wrist center\n",
    "    x,y = [],[]\n",
    "    for i in range(slice5):\n",
    "        cnt = th_li[i + upper].count(255)\n",
    "        index = th_li[i + upper].index(255)\n",
    "        x.append([i+upper])\n",
    "        y.append([int((index*2 + cnt - 1)/2)])\n",
    "\n",
    "    # x, y / draw regression line\n",
    "    model = LinearRegression()\n",
    "    model.fit(X=x,y=y)\n",
    "\n",
    "    # Rotation stage 02\n",
    "    angle = math.atan2(h - 0, int(model.predict([[h]])) - int(model.predict([[0]])))*180/math.pi\n",
    "    M = cv2.getRotationMatrix2D((w/2,h/2), angle-90, 1)\n",
    "    rotate = cv2.warpAffine(before_rot_img, M, (w, h))\n",
    "\n",
    "    # Cutting img (rotated img)\n",
    "    for i in range(len(th[-1])):\n",
    "        if th[-1][i] == 255:\n",
    "            start_x = i\n",
    "            break\n",
    "\n",
    "    for i in range(len(th[-1])):\n",
    "        if th[-1][i] == 255:\n",
    "            end_x = i\n",
    "            \n",
    "            \n",
    "    s_point = h - int((int(model.predict([[h]])-start_x)) * math.tan(math.pi*((90-angle)/180)))\n",
    "    e_point = h - int((end_x - int(model.predict([[h]]))) * math.tan(math.pi*((angle-90)/180)))\n",
    "    point = max(s_point, e_point)\n",
    "    rotated_img = rotate[:point]\n",
    "    return rotated_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 발기조절, 대비, 필터링 작업으로 뼈 추출하는 함수\n",
    "### img, morphology_value_1, morphology_value_2, filter_value(a,b)\n",
    "def Decomposing(rotated_img,a,b,d,e):\n",
    "\n",
    "    ######## Decomposing_stage_1 / [ Contours , Mask ] ########\n",
    "    decomp_img_1 = rotated_img.copy()\n",
    "\n",
    "    ## Adjusting brighness\n",
    "    d_img1 = decomp_img_1.copy()\n",
    "    cols, rows = d_img1.shape[:2]\n",
    "    brightness1 = np.sum(d_img1) / (255 * cols * rows)\n",
    "\n",
    "    if brightness1 > 0.8:\n",
    "        decomp_img_1 = np.clip(decomp_img_1 - 80., 0, 255).astype(np.uint8)\n",
    "    elif brightness1 > 0.75:\n",
    "        decomp_img_1 = np.clip(decomp_img_1 - 50., 0, 255).astype(np.uint8)\n",
    "    elif brightness1 > 0.65:\n",
    "        decomp_img_1 = np.clip(decomp_img_1 - 30., 0, 255).astype(np.uint8)\n",
    "    else: decomp_img_1 = np.clip(decomp_img_1 - 10., 0, 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "    ## change to Lab\n",
    "    decomp_img_1 = cv2.cvtColor(decomp_img_1, cv2.COLOR_RGB2BGR)\n",
    "    decomp_img_1 = cv2.cvtColor(decomp_img_1, cv2.COLOR_BGR2Lab)\n",
    "\n",
    "    ## Morphology\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_CROSS, (a, a))\n",
    "    decomp_img_1 = cv2.morphologyEx(decomp_img_1, cv2.MORPH_TOPHAT, k) # Emphasis\n",
    "\n",
    "    ## Filter\n",
    "    decomp_img_1 = cv2.bilateralFilter(decomp_img_1,-1, d, e)\n",
    "\n",
    "    ## Lab to gray for binary\n",
    "    decomp_img_1 = cv2.cvtColor(decomp_img_1, cv2.COLOR_Lab2BGR)\n",
    "    decomp_img_1 = cv2.cvtColor(decomp_img_1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    ## img_normalization\n",
    "    decomp_img_1 = cv2.normalize(decomp_img_1, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "    ## CLAHE\n",
    "    decomp_img_1 = cv2.equalizeHist(decomp_img_1)\n",
    "    clahe = cv2.createCLAHE(clipLimit=1.0, tileGridSize=(3,3)) \n",
    "    decomp_img_1= clahe.apply(decomp_img_1)          \n",
    "\n",
    "\n",
    "    ## Threshold / value = img.mean()\n",
    "    ret, mask = cv2.threshold(decomp_img_1,\n",
    "                            np.mean(decomp_img_1),\n",
    "                            255,\n",
    "                            cv2.THRESH_BINARY) \n",
    "\n",
    "    ## Extract object / same value pixels\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(mask, \n",
    "                                            cv2.RETR_EXTERNAL, # only outline\n",
    "                                            cv2.CHAIN_APPROX_SIMPLE) # Contour vertex coordinate\n",
    "\n",
    "    ## drawing Contours\n",
    "    cv2.drawContours(mask, contours, -1, (255,255,255), -1) # -1: 모든 컨트어 표시 /color/ fill\n",
    "\n",
    "\n",
    "        \n",
    "    ######## Decomposing_stage_2 / [ Brightness_Empahsis ] ########\n",
    "    decomp_img_2 = rotated_img.copy()\n",
    "\n",
    "    ## Brightness_Empahsis\n",
    "    d_img2 = decomp_img_2.copy()\n",
    "    cols, rows = d_img2.shape[:2]\n",
    "    brightness2 = np.sum(d_img2) / (255 * cols * rows)\n",
    "\n",
    "    ## Empahsis\n",
    "    if brightness2 > 0.8:\n",
    "        decomp_img_2 = np.clip(decomp_img_2 - 80., 0, 255).astype(np.uint8)\n",
    "    elif brightness2 > 0.75:\n",
    "        decomp_img_2 = np.clip(decomp_img_2 - 50., 0, 255).astype(np.uint8)\n",
    "    elif brightness2 > 0.65:\n",
    "        decomp_img_2 = np.clip(decomp_img_2 - 30., 0, 255).astype(np.uint8)\n",
    "    else: decomp_img_2 = np.clip(decomp_img_2 - 10., 0, 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "    ## Morphology\n",
    "    k2 = cv2.getStructuringElement(cv2.MORPH_CROSS,(b,b))\n",
    "    decomp_img_2 = cv2.morphologyEx(decomp_img_2, cv2.MORPH_TOPHAT, k2)\n",
    "\n",
    "    ## contrast\n",
    "    decomp_img_2 = cv2.cvtColor(decomp_img_2, cv2.COLOR_BGR2RGB)\n",
    "    decomp_img_2 = cv2.cvtColor(decomp_img_2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    if decomp_img_2.mean() <= 15:\n",
    "        low = decomp_img_2.mean() * 3.2\n",
    "        high = decomp_img_2.mean() * 3.6\n",
    "    elif decomp_img_2.mean() <= 20:\n",
    "        low = decomp_img_2.mean() * 3\n",
    "        high = decomp_img_2.mean() * 3.6\n",
    "    else:\n",
    "        low = decomp_img_2.mean() * 3\n",
    "        high = decomp_img_2.mean() * 3.7\n",
    "\n",
    "    decomp_img_2 = cv2.blur(decomp_img_2,(2,2))\n",
    "    h, w = decomp_img_2.shape\n",
    "    img_ = np.zeros(decomp_img_2.shape, dtype=np.uint8)\n",
    "\n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            temp = int((255 / (high - low)) * (decomp_img_2[y][x] - low))\n",
    "            if temp > 255:\n",
    "                img_[y][x] = 255\n",
    "            elif temp < 0:\n",
    "                img_[y][x] = 0\n",
    "            else:\n",
    "                img_[y][x] = temp\n",
    "\n",
    "    decomp_img_2 = img_.copy()\n",
    "\n",
    "\n",
    "    ######## Decomposing_Final_stage / [ Result ] ########\n",
    "    ### Bone empahsis / bitwise (mask)\n",
    "    ## Morphology\n",
    "    ## Contours\n",
    "    contours, hierarchy = cv2.findContours(decomp_img_2, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cv2.drawContours(decomp_img_2, contours, -1, (255, 255, 255), -1)\n",
    "\n",
    "    ## Bitwise (mask) / print white parts\n",
    "\n",
    "    decomp_img_2 = cv2.bitwise_and(decomp_img_2, mask) \n",
    "\n",
    "    decomp_img_2 = cv2.cvtColor(decomp_img_2, cv2.COLOR_GRAY2BGR)\n",
    "    decomp_img_2 = cv2.blur(decomp_img_2,(2,2))\n",
    "\n",
    "    bone_extraction = cv2.resize(decomp_img_2, (600, 800))\n",
    "\n",
    "    return bone_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뼈 윤곽선만 추출하는 함수\n",
    "def outline_bone(bone_extraction):\n",
    "    kernel = np.ones((11, 11), np.uint8)\n",
    "    result = cv2.morphologyEx(bone_extraction, cv2.MORPH_CLOSE, kernel)\n",
    "    canny_test = cv2.Canny(result, 50, 53)\n",
    "\n",
    "    img_test = canny_test.copy()\n",
    "\n",
    "    # 윤곽선 확대\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    dst = cv2.dilate(img_test, k)\n",
    "    thick_line = dst.copy()\n",
    "\n",
    "    # 노이즈 제거\n",
    "    denoised_img = cv2.fastNlMeansDenoising(thick_line, h=50, templateWindowSize = 10, searchWindowSize = 21 )\n",
    "    delete_noise = denoised_img.copy()\n",
    "\n",
    "    #윤곽선 삭제\n",
    "    im = cv2.normalize(delete_noise, None, alpha=0, beta= 255, norm_type = cv2.NORM_MINMAX)\n",
    "    res, im = cv2.threshold(im, 20, 255,cv2.THRESH_BINARY)\n",
    "\n",
    "    cv2.floodFill(im, None, (0,0), 255)\n",
    "    cv2.floodFill(im, None, (0,0), 0)\n",
    "\n",
    "    no_boder = im.copy()\n",
    "\n",
    "    return no_boder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bone_extraction(path):\n",
    "    try:\n",
    "        resize_img = read_img(path)\n",
    "        mask = make_mask(resize_img)\n",
    "        masked = cut_mask(resize_img, mask)\n",
    "        rotated_img = img_rotation(masked)\n",
    "        bone = Decomposing(rotated_img,60,55,50,25)\n",
    "        return bone\n",
    "    \n",
    "    except:\n",
    "        print('ERROR > Please check again' )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 경로\n",
    "path = '../BoneAge/Data/image_F/'\n",
    "original_img_path = glob.glob(path + \"*.jpg\")\n",
    "process_img_path = '../BoneAge/Data/process_image/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 이미지 전체 전처리 진행\n",
    "for i in original_img_path:\n",
    "    bone = Bone_extraction(i)\n",
    "\n",
    "    file_name = os.path.basename(i)\n",
    "    save_path = os.path.join(process_img_path, file_name)\n",
    "    cv2.imwrite(save_path, bone)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
